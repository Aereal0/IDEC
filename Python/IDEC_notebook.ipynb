{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c8d7cd4-3286-4d07-9efd-27441251ff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§© Imported autoencoder from: /home/USERS/didac.reyes/TFG/Python IDEC/dec_utils.py\n",
      "<__main__.Args object at 0x7fb01a7c15b0>\n",
      "MNIST samples (70000, 784)\n",
      "âš™ï¸  Pretraining autoencoder...\n",
      "...Pretraining...\n",
      "Epoch 1/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 849us/steposs: 0.0532  \n",
      "        |==>  acc: 0.5578,  nmi: 0.5021  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 0.0531\n",
      "Epoch 2/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0224 \n",
      "Epoch 3/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0192 \n",
      "Epoch 4/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0175 \n",
      "Epoch 5/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 \n",
      "Epoch 6/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0157 \n",
      "Epoch 7/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0151 \n",
      "Epoch 8/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0144 \n",
      "Epoch 9/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0140 \n",
      "Epoch 10/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0136 \n",
      "Epoch 11/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0134 \n",
      "Epoch 12/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0130 \n",
      "Epoch 13/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0128 \n",
      "Epoch 14/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0125 \n",
      "Epoch 15/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0123 \n",
      "Epoch 16/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0122 \n",
      "Epoch 17/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0120 \n",
      "Epoch 18/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 \n",
      "Epoch 19/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0117 \n",
      "Epoch 20/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 \n",
      "Epoch 21/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 \n",
      "Epoch 22/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0112 \n",
      "Epoch 23/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0112 \n",
      "Epoch 24/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0111 \n",
      "Epoch 25/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0109 \n",
      "Epoch 26/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0109 \n",
      "Epoch 27/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0108 \n",
      "Epoch 28/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0107 \n",
      "Epoch 29/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0106 \n",
      "Epoch 30/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0106 \n",
      "Epoch 31/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/steposs: 0.0105 \n",
      "        |==>  acc: 0.8219,  nmi: 0.7543  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0105\n",
      "Epoch 32/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0104 \n",
      "Epoch 33/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0104 \n",
      "Epoch 34/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0102 \n",
      "Epoch 35/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0102 \n",
      "Epoch 36/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0101 \n",
      "Epoch 37/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0101 \n",
      "Epoch 38/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0100 \n",
      "Epoch 39/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0100 \n",
      "Epoch 40/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0100 \n",
      "Epoch 41/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0098 \n",
      "Epoch 42/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0098 \n",
      "Epoch 43/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0098 \n",
      "Epoch 44/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0097 \n",
      "Epoch 45/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0097 \n",
      "Epoch 46/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0097 \n",
      "Epoch 47/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0096 \n",
      "Epoch 48/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0096 \n",
      "Epoch 49/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0095 \n",
      "Epoch 50/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0095 \n",
      "Epoch 51/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0094 \n",
      "Epoch 52/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0094 \n",
      "Epoch 53/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0094 \n",
      "Epoch 54/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0093 \n",
      "Epoch 55/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0093 \n",
      "Epoch 56/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0093 \n",
      "Epoch 57/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0092 \n",
      "Epoch 58/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0092 \n",
      "Epoch 59/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0092 \n",
      "Epoch 60/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0091 \n",
      "Epoch 61/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/steposs: 0.0091 \n",
      "        |==>  acc: 0.8359,  nmi: 0.7729  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0091\n",
      "Epoch 62/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0091 \n",
      "Epoch 63/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0091 \n",
      "Epoch 64/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0091 \n",
      "Epoch 65/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0090 \n",
      "Epoch 66/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0090 \n",
      "Epoch 67/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0090 \n",
      "Epoch 68/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0089 \n",
      "Epoch 69/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0089 \n",
      "Epoch 70/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0089 \n",
      "Epoch 71/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0088 \n",
      "Epoch 72/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0088 \n",
      "Epoch 73/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0088 \n",
      "Epoch 74/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0088 \n",
      "Epoch 75/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 76/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0088 \n",
      "Epoch 77/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 78/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 79/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 80/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0086 \n",
      "Epoch 81/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 82/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 \n",
      "Epoch 83/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0086 \n",
      "Epoch 84/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0086 \n",
      "Epoch 85/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0086 \n",
      "Epoch 86/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 87/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 88/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 89/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 90/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 91/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/steposs: 0.0085 \n",
      "        |==>  acc: 0.8361,  nmi: 0.7706  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0085\n",
      "Epoch 92/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 93/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 \n",
      "Epoch 94/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 95/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 96/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 97/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 98/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 99/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 100/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 101/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 102/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 103/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 104/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 \n",
      "Epoch 105/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 106/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 107/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 108/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 109/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 110/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 111/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 112/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 113/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 114/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 \n",
      "Epoch 115/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 116/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 117/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 118/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 119/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 120/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 121/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/steposs: 0.0081 \n",
      "        |==>  acc: 0.8365,  nmi: 0.7717  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0081\n",
      "Epoch 122/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 123/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 124/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 \n",
      "Epoch 125/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 126/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 127/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 128/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 129/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 130/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 131/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 \n",
      "Epoch 132/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 133/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 134/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 135/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 136/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 137/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 138/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 139/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 140/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 141/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 \n",
      "Epoch 142/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 143/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 144/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 145/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 146/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 147/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 148/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 149/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 150/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 151/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 694us/steposs: 0.0078 \n",
      "        |==>  acc: 0.8410,  nmi: 0.7756  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0078\n",
      "Epoch 152/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 153/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 154/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 155/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 156/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 157/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 158/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 \n",
      "Epoch 159/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 160/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 161/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 162/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 163/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 164/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 165/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 166/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 167/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 168/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 169/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 170/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 171/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 172/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 \n",
      "Epoch 173/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 174/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 175/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 176/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 177/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 178/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 179/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 180/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 181/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 701us/steposs: 0.0075 \n",
      "        |==>  acc: 0.8337,  nmi: 0.7690  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0075\n",
      "Epoch 182/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 183/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 184/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 185/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 186/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 187/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 188/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 \n",
      "Epoch 189/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 190/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 191/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 192/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 193/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 194/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 195/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 196/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 197/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 198/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 199/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 200/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 201/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 202/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 203/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 204/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 205/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 206/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 207/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 208/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 209/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 210/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 211/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/steposs: 0.0074 \n",
      "        |==>  acc: 0.8398,  nmi: 0.7734  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0074\n",
      "Epoch 212/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 213/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 214/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 215/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 216/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 217/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 218/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 219/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 220/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 221/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 222/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 223/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 224/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 225/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 226/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 227/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 228/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 229/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 230/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 231/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 232/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 233/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 234/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 235/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 236/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 237/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 238/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 239/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 240/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 241/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/steposs: 0.0073 \n",
      "        |==>  acc: 0.8327,  nmi: 0.7676  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0073\n",
      "Epoch 242/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 243/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 244/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 245/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 246/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 247/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 248/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 249/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 250/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 251/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 252/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 253/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 254/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 255/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 256/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 257/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 258/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 259/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 260/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 261/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 262/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 \n",
      "Epoch 263/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 264/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 265/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 266/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 267/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 268/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 269/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 270/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 271/300\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 685us/steposs: 0.0072 \n",
      "        |==>  acc: 0.8309,  nmi: 0.7660  <==|\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0072\n",
      "Epoch 272/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 273/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 274/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 275/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 276/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 277/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 278/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 279/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 280/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 281/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 282/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 283/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 284/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 285/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 286/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 \n",
      "Epoch 287/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 288/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 289/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 290/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 291/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 292/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 293/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 294/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 295/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 296/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 297/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 298/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 299/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Epoch 300/300\n",
      "\u001b[1m274/274\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 \n",
      "Pretraining time: 214s\n",
      "âœ… Pretrained AE weights saved to ./ae_weights/ae_weights.weights.h5\n",
      "Pretrained AE weights are loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">392,500</span> â”‚ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> â”‚ encoder_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,002,000</span> â”‚ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,010</span> â”‚ encoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,000</span> â”‚ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,500</span> â”‚ decoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> â”‚ decoder_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ clustering          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> â”‚ encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ClusteringLayer</span>)   â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">392,784</span> â”‚ decoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input (\u001b[38;5;33mInputLayer\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_0 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)       â”‚    \u001b[38;5;34m392,500\u001b[0m â”‚ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_1 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)       â”‚    \u001b[38;5;34m250,500\u001b[0m â”‚ encoder_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_2 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      â”‚  \u001b[38;5;34m1,002,000\u001b[0m â”‚ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ encoder_3 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        â”‚     \u001b[38;5;34m20,010\u001b[0m â”‚ encoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_3 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      â”‚     \u001b[38;5;34m22,000\u001b[0m â”‚ encoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_2 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)       â”‚  \u001b[38;5;34m1,000,500\u001b[0m â”‚ decoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_1 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)       â”‚    \u001b[38;5;34m250,500\u001b[0m â”‚ decoder_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ clustering          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        â”‚        \u001b[38;5;34m100\u001b[0m â”‚ encoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mClusteringLayer\u001b[0m)   â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_0 (\u001b[38;5;33mDense\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)       â”‚    \u001b[38;5;34m392,784\u001b[0m â”‚ decoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,330,894</span> (12.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,330,894\u001b[0m (12.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,330,894</span> (12.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,330,894\u001b[0m (12.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting clustering training...\n",
      "Update interval 140\n",
      "Save interval 1367.1875\n",
      "Initializing cluster centers with k-means.\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 737us/step\n",
      "Iter 0 : Acc 0.83296 , nmi 0.76768 , ari 0.72254 ; loss= [0 0 0]\n",
      "saving model to: ./results/idec/IDEC_model_0.weights.h5\n",
      "Iter 140 : Acc 0.84956 , nmi 0.79209 , ari 0.75507 ; loss= [0.01221 0.04499 0.00771]\n",
      "Iter 280 : Acc 0.86243 , nmi 0.81412 , ari 0.78146 ; loss= [0.01513 0.06548 0.00858]\n",
      "Iter 420 : Acc 0.87207 , nmi 0.82969 , ari 0.79912 ; loss= [0.01901 0.09341 0.00968]\n",
      "Iter 560 : Acc 0.8772 , nmi 0.84085 , ari 0.81004 ; loss= [0.02325 0.12588 0.01066]\n",
      "Iter 700 : Acc 0.87983 , nmi 0.84848 , ari 0.8178 ; loss= [0.02664 0.15145 0.0115 ]\n",
      "Iter 840 : Acc 0.88046 , nmi 0.85263 , ari 0.82128 ; loss= [0.02894 0.16896 0.01204]\n",
      "Iter 980 : Acc 0.8814 , nmi 0.8547 , ari 0.8231 ; loss= [0.03042 0.17997 0.01242]\n",
      "Iter 1120 : Acc 0.88097 , nmi 0.85581 , ari 0.82362 ; loss= [0.03138 0.18671 0.01271]\n",
      "Iter 1260 : Acc 0.88089 , nmi 0.85633 , ari 0.82434 ; loss= [0.03196 0.19064 0.0129 ]\n",
      "Iter 1400 : Acc 0.88094 , nmi 0.85666 , ari 0.82448 ; loss= [0.03231 0.19267 0.01305]\n",
      "Iter 1540 : Acc 0.88124 , nmi 0.85701 , ari 0.82494 ; loss= [0.03252 0.19342 0.01318]\n",
      "Iter 1680 : Acc 0.88099 , nmi 0.85715 , ari 0.82513 ; loss= [0.03257 0.19309 0.01326]\n",
      "Iter 1820 : Acc 0.88161 , nmi 0.85791 , ari 0.8257 ; loss= [0.03253 0.19213 0.01332]\n",
      "Iter 1960 : Acc 0.88149 , nmi 0.8579 , ari 0.82568 ; loss= [0.03242 0.19058 0.01337]\n",
      "Iter 2100 : Acc 0.88149 , nmi 0.85764 , ari 0.8254 ; loss= [0.03228 0.18874 0.0134 ]\n",
      "Iter 2240 : Acc 0.88184 , nmi 0.8582 , ari 0.82598 ; loss= [0.0321  0.18664 0.01344]\n",
      "Iter 2380 : Acc 0.88186 , nmi 0.85848 , ari 0.82636 ; loss= [0.0319  0.18439 0.01346]\n",
      "Iter 2520 : Acc 0.88203 , nmi 0.85875 , ari 0.82657 ; loss= [0.03169 0.18206 0.01349]\n",
      "Iter 2660 : Acc 0.88197 , nmi 0.8587 , ari 0.82658 ; loss= [0.03146 0.17961 0.0135 ]\n",
      "Iter 2800 : Acc 0.88191 , nmi 0.85867 , ari 0.82655 ; loss= [0.03118 0.1771  0.01347]\n",
      "Iter 2940 : Acc 0.88194 , nmi 0.85863 , ari 0.82649 ; loss= [0.0309  0.17455 0.01345]\n",
      "Iter 3080 : Acc 0.88189 , nmi 0.85853 , ari 0.82639 ; loss= [0.03063 0.17203 0.01343]\n",
      "Iter 3220 : Acc 0.88193 , nmi 0.8587 , ari 0.82653 ; loss= [0.03037 0.16955 0.01342]\n",
      "Iter 3360 : Acc 0.8816 , nmi 0.8586 , ari 0.82641 ; loss= [0.03011 0.16713 0.0134 ]\n",
      "Iter 3500 : Acc 0.88166 , nmi 0.85857 , ari 0.82638 ; loss= [0.02986 0.16473 0.01339]\n",
      "Iter 3640 : Acc 0.88134 , nmi 0.85853 , ari 0.82628 ; loss= [0.02961 0.16241 0.01337]\n",
      "Iter 3780 : Acc 0.88137 , nmi 0.85879 , ari 0.8265 ; loss= [0.02938 0.16013 0.01337]\n",
      "Iter 3920 : Acc 0.88129 , nmi 0.85866 , ari 0.82637 ; loss= [0.02913 0.1579  0.01334]\n",
      "Iter 4060 : Acc 0.88109 , nmi 0.85846 , ari 0.8261 ; loss= [0.02889 0.1557  0.01332]\n",
      "Iter 4200 : Acc 0.88119 , nmi 0.85856 , ari 0.82627 ; loss= [0.02866 0.15358 0.0133 ]\n",
      "Iter 4340 : Acc 0.88106 , nmi 0.85858 , ari 0.82626 ; loss= [0.02843 0.1515  0.01328]\n",
      "Iter 4480 : Acc 0.88116 , nmi 0.85867 , ari 0.82636 ; loss= [0.0282  0.14947 0.01325]\n",
      "Iter 4620 : Acc 0.88119 , nmi 0.85863 , ari 0.82635 ; loss= [0.02798 0.14746 0.01323]\n",
      "Iter 4760 : Acc 0.88109 , nmi 0.8586 , ari 0.8263 ; loss= [0.02776 0.14552 0.01321]\n",
      "Iter 4900 : Acc 0.88109 , nmi 0.85864 , ari 0.82632 ; loss= [0.02758 0.14365 0.01321]\n",
      "Iter 5040 : Acc 0.88121 , nmi 0.85864 , ari 0.82635 ; loss= [0.02739 0.14188 0.01321]\n",
      "Iter 5180 : Acc 0.88111 , nmi 0.85862 , ari 0.8263 ; loss= [0.02722 0.14015 0.01321]\n",
      "Iter 5320 : Acc 0.88116 , nmi 0.85866 , ari 0.82634 ; loss= [0.02705 0.13848 0.0132 ]\n",
      "Iter 5460 : Acc 0.88111 , nmi 0.85865 , ari 0.82633 ; loss= [0.02687 0.13683 0.01319]\n",
      "Iter 5600 : Acc 0.88104 , nmi 0.85865 , ari 0.82632 ; loss= [0.02669 0.1352  0.01317]\n",
      "Iter 5740 : Acc 0.88104 , nmi 0.85859 , ari 0.82627 ; loss= [0.02651 0.13358 0.01315]\n",
      "Iter 5880 : Acc 0.88107 , nmi 0.85867 , ari 0.82632 ; loss= [0.02633 0.13203 0.01313]\n",
      "Iter 6020 : Acc 0.88089 , nmi 0.85836 , ari 0.82595 ; loss= [0.02615 0.13048 0.0131 ]\n",
      "Iter 6160 : Acc 0.88103 , nmi 0.85866 , ari 0.82634 ; loss= [0.02597 0.12899 0.01307]\n",
      "Iter 6300 : Acc 0.88103 , nmi 0.85869 , ari 0.82637 ; loss= [0.0258  0.12751 0.01305]\n",
      "Iter 6440 : Acc 0.88104 , nmi 0.85877 , ari 0.82645 ; loss= [0.02564 0.1261  0.01303]\n",
      "Iter 6580 : Acc 0.88151 , nmi 0.859 , ari 0.82679 ; loss= [0.02548 0.12472 0.01301]\n",
      "Iter 6720 : Acc 0.88146 , nmi 0.85882 , ari 0.82658 ; loss= [0.02533 0.12339 0.01299]\n",
      "Iter 6860 : Acc 0.88126 , nmi 0.8589 , ari 0.82663 ; loss= [0.02518 0.1221  0.01297]\n",
      "Iter 7000 : Acc 0.88117 , nmi 0.85874 , ari 0.82645 ; loss= [0.02504 0.12083 0.01295]\n",
      "Iter 7140 : Acc 0.88126 , nmi 0.85878 , ari 0.8265 ; loss= [0.0249  0.11958 0.01294]\n",
      "Iter 7280 : Acc 0.88113 , nmi 0.85872 , ari 0.82642 ; loss= [0.02476 0.11837 0.01292]\n",
      "Iter 7420 : Acc 0.88119 , nmi 0.85875 , ari 0.82646 ; loss= [0.02463 0.11717 0.01291]\n",
      "delta_label  7.142857142857143e-05 < tol  0.0001\n",
      "Reached tolerance threshold. Stopping training.\n",
      "saving model to: ./results/idec/IDEC_model_final.weights.h5\n",
      "âœ… Clustering finished in 208s\n",
      "ðŸ“Š Final ACC: 0.8811857142857142\n",
      "ðŸ“Š Final NMI: 0.858751924615851\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementation for Improved Deep Embedded Clustering as described in paper:\n",
    "\n",
    "        Xifeng Guo, Long Gao, Xinwang Liu, Jianping Yin. Improved Deep Embedded Clustering with Local Structure\n",
    "        Preservation. IJCAI 2017.\n",
    "\n",
    "Usage:\n",
    "    Weights of Pretrained autoencoder for mnist are in './ae_weights/mnist_ae_weights.h5':\n",
    "        python IDEC.py mnist --ae_weights ./ae_weights/mnist_ae_weights.h5\n",
    "    for USPS and REUTERSIDF10K datasets\n",
    "        python IDEC.py usps --update_interval 30 --ae_weights ./ae_weights/usps_ae_weights.h5\n",
    "        python IDEC.py reutersidf10k --n_clusters 4 --update_interval 3 --ae_weights ./ae_weights/reutersidf10k_ae_weights.h5\n",
    "\n",
    "Author:\n",
    "    Xifeng Guo. 2017.4.30\n",
    "\"\"\"\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import csv\n",
    "from keras.models import Model\n",
    "from keras import callbacks\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "from dec_utils import cluster_acc, ClusteringLayer, autoencoder\n",
    "print(\"ðŸ§© Imported autoencoder from:\", autoencoder.__code__.co_filename)\n",
    "\n",
    "class IDEC(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 n_clusters=10,\n",
    "                 alpha=1.0,\n",
    "                 batch_size=256,\n",
    "                 init='glorot_uniform'):\n",
    "\n",
    "        super(IDEC, self).__init__()\n",
    "\n",
    "        self.dims = dims\n",
    "        self.input_dim = dims[0]\n",
    "        self.n_stacks = len(self.dims) - 1\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.autoencoder, self.encoder = autoencoder(self.dims, init=init)\n",
    "\n",
    "    def pretrain(self, x, y=None, optimizer='adam', epochs=200, batch_size=256, save_dir='results/temp'):\n",
    "        print('...Pretraining...')\n",
    "        self.autoencoder.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        csv_logger = callbacks.CSVLogger(os.path.join(save_dir, 'pretrain_log.csv'))\n",
    "        cb = [csv_logger]\n",
    "\n",
    "        if y is not None:\n",
    "            class PrintACC(callbacks.Callback):\n",
    "                def __init__(self, x, y, encoder):\n",
    "                    super(PrintACC, self).__init__()\n",
    "                    self.x = x\n",
    "                    self.y = y\n",
    "                    self.encoder = encoder\n",
    "\n",
    "                def on_epoch_end(self, epoch, logs=None):\n",
    "                    if int(epochs / 10) != 0 and epoch % int(epochs / 10) != 0:\n",
    "                        return\n",
    "                    features = self.encoder.predict(self.x)\n",
    "                    km = KMeans(n_clusters=len(np.unique(self.y)), n_init=20)\n",
    "                    y_pred = km.fit_predict(features)\n",
    "                    acc = cluster_acc(self.y, y_pred)\n",
    "                    nmi = metrics.normalized_mutual_info_score(self.y, y_pred)\n",
    "                    print(f'        |==>  acc: {acc:.4f},  nmi: {nmi:.4f}  <==|')\n",
    "\n",
    "            cb.append(PrintACC(x, y, self.encoder))\n",
    "\n",
    "        t0 = time()\n",
    "        self.autoencoder.fit(x, x, batch_size=batch_size, epochs=epochs, callbacks=cb)\n",
    "        print('Pretraining time: %ds' % round(time() - t0))\n",
    "\n",
    "        save_path = os.path.join(save_dir, 'ae_weights.weights.h5')\n",
    "        self.autoencoder.save_weights(save_path)\n",
    "        print(f'âœ… Pretrained AE weights saved to {save_path}')\n",
    "    \n",
    "    def initialize_model(self, ae_weights=None, gamma=0.1, optimizer='adam'):\n",
    "        if ae_weights is not None:\n",
    "            self.encoder.load_weights(ae_weights)\n",
    "            print( 'Pretrained AE weights are loaded successfully.')\n",
    "        else:\n",
    "            print('ae_weights must be given. E.g.')\n",
    "            print('python IDEC.py mnist --ae_weights weights.h5')\n",
    "            exit()\n",
    "\n",
    "        hidden = self.encoder.get_layer(name='encoder_%d' % (self.n_stacks - 1)).output\n",
    "        clustering_layer = ClusteringLayer(self.n_clusters, name='clustering')(hidden)\n",
    "\n",
    "        self.model = Model(inputs=self.autoencoder.input,\n",
    "                   outputs=[clustering_layer, self.autoencoder.output])\n",
    "        self.model.compile(loss={'clustering': 'kld', 'decoder_0': 'mse'},\n",
    "                           loss_weights=[gamma, 1],\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "    def load_weights(self, weights_path):  # load weights of IDEC model\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def extract_feature(self, x):  # extract features from before clustering layer\n",
    "        encoder = Model(self.model.input, self.model.get_layer('encoder_%d' % (self.n_stacks - 1)).output)\n",
    "        return encoder.predict(x)\n",
    "\n",
    "    def predict_clusters(self, x):  # predict cluster labels using the output of clustering layer\n",
    "        q, _ = self.model.predict(x, verbose=1)\n",
    "        return q.argmax(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def target_distribution(q):  # target distribution P which enhances the discrimination of soft label Q\n",
    "        weight = q ** 2 / q.sum(0)\n",
    "        return (weight.T / weight.sum(1)).T\n",
    "\n",
    "    def clustering(self, x, y=None,\n",
    "                   tol=1e-3,\n",
    "                   update_interval=140,\n",
    "                   maxiter=2e4,\n",
    "                   save_dir='./results/idec'):\n",
    "\n",
    "        print('Update interval', update_interval)\n",
    "        save_interval = x.shape[0] / self.batch_size * 5  # 5 epochs\n",
    "        print('Save interval', save_interval)\n",
    "\n",
    "        # initialize cluster centers using k-means\n",
    "        print('Initializing cluster centers with k-means.')\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        y_pred = kmeans.fit_predict(self.encoder.predict(x))\n",
    "        y_pred_last = y_pred\n",
    "        self.model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "        # logging file\n",
    "        import csv, os\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        logfile = open(os.path.join(save_dir, 'idec_log.csv'), mode='w', newline='')\n",
    "        logwriter = csv.DictWriter(logfile, fieldnames=['iter', 'acc', 'nmi', 'ari', 'L', 'Lc', 'Lr'])\n",
    "        logwriter.writeheader()\n",
    "\n",
    "        loss = [0, 0, 0]\n",
    "        index = 0\n",
    "        for ite in range(int(maxiter)):\n",
    "            if ite % update_interval == 0:\n",
    "                q, _ = self.model.predict(x, verbose=0)\n",
    "                p = self.target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "                # evaluate the clustering performance\n",
    "                y_pred = q.argmax(1)\n",
    "                delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "                y_pred_last = y_pred\n",
    "                if y is not None:\n",
    "                    acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "                    nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "                    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "                    loss = np.round(loss, 5)\n",
    "                    logdict = dict(iter=ite, acc=acc, nmi=nmi, ari=ari, L=loss[0], Lc=loss[1], Lr=loss[2])\n",
    "                    logwriter.writerow(logdict)\n",
    "                    print('Iter', ite, ': Acc', acc, ', nmi', nmi, ', ari', ari, '; loss=', loss)\n",
    "\n",
    "                # check stop criterion\n",
    "                if ite > 0 and delta_label < tol:\n",
    "                    print('delta_label ', delta_label, '< tol ', tol)\n",
    "                    print('Reached tolerance threshold. Stopping training.')\n",
    "                    logfile.close()\n",
    "                    break\n",
    "\n",
    "            # train on batch\n",
    "            if (index + 1) * self.batch_size > x.shape[0]:\n",
    "                loss = self.model.train_on_batch(x=x[index * self.batch_size::],\n",
    "                                                 y=[p[index * self.batch_size::], x[index * self.batch_size::]])\n",
    "                index = 0\n",
    "            else:\n",
    "                loss = self.model.train_on_batch(x=x[index * self.batch_size:(index + 1) * self.batch_size],\n",
    "                                                 y=[p[index * self.batch_size:(index + 1) * self.batch_size],\n",
    "                                                    x[index * self.batch_size:(index + 1) * self.batch_size]])\n",
    "                index += 1\n",
    "\n",
    "            # save intermediate model\n",
    "            if ite % save_interval == 0:\n",
    "                # save IDEC model checkpoints\n",
    "                self.model.save_weights(save_dir + '/IDEC_model_' + str(ite) + '.weights.h5')\n",
    "                print('saving model to:', save_dir + '/IDEC_model_' + str(ite) + '.weights.h5')\n",
    "\n",
    "            ite += 1\n",
    "\n",
    "        # save the trained model\n",
    "        logfile.close()\n",
    "        self.model.save_weights(save_dir + '/IDEC_model_final.weights.h5')\n",
    "        print('saving model to:', save_dir + '/IDEC_model_final.weights.h5')\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # === HiperparÃ¡metros ===\n",
    "    class Args:\n",
    "        dataset = 'mnist'\n",
    "        n_clusters = 10\n",
    "        batch_size = 256\n",
    "        maxiter = int(2e4)\n",
    "        gamma = 0.1\n",
    "        update_interval = 140\n",
    "        tol = 1e-4\n",
    "        ae_weights = './ae_weights/ae_weights.weights.h5'\n",
    "        save_dir = './results/idec'\n",
    "\n",
    "    args = Args()\n",
    "    print(args)\n",
    "\n",
    "    # === Cargar dataset ===\n",
    "    from datasets import load_mnist, load_usps, load_reuters\n",
    "    if args.dataset == 'mnist':\n",
    "        x, y = load_mnist()\n",
    "    elif args.dataset == 'usps':\n",
    "        x, y = load_usps('data/usps')\n",
    "    elif args.dataset == 'reutersidf10k':\n",
    "        x, y = load_reuters('data/reuters')\n",
    "\n",
    "    # === Crear modelo IDEC ===\n",
    "    idec = IDEC(dims=[x.shape[-1], 500, 500, 2000, 10], n_clusters=args.n_clusters)\n",
    "\n",
    "    # === Pretraining (solo si no existen pesos) ===\n",
    "    if args.ae_weights is None or not os.path.exists(args.ae_weights):\n",
    "        print(\"âš™ï¸  Pretraining autoencoder...\")\n",
    "        idec.pretrain(x=x, y=y, optimizer='adam', epochs=300, batch_size=args.batch_size ,save_dir=os.path.dirname(args.ae_weights))\n",
    "        args.ae_weights = args.ae_weights  # ya se guarda en ese path\n",
    "    else:\n",
    "        print(\"ðŸ“‚ Loading pretrained weights...\")\n",
    "        idec.autoencoder.load_weights(args.ae_weights)\n",
    "\n",
    "    # === Inicializar modelo clustering ===\n",
    "    idec.initialize_model(ae_weights=args.ae_weights, gamma=args.gamma, optimizer='adam')\n",
    "\n",
    "    # === Clustering ===\n",
    "    idec.model.summary()\n",
    "    print(\"ðŸš€ Starting clustering training...\")\n",
    "    t0 = time()\n",
    "    y_pred = idec.clustering(x, y=y, tol=args.tol, maxiter=args.maxiter,\n",
    "                             update_interval=args.update_interval, save_dir=args.save_dir)\n",
    "    print(f\"âœ… Clustering finished in {round(time() - t0)}s\")\n",
    "    print(\"ðŸ“Š Final ACC:\", cluster_acc(y, y_pred))\n",
    "    print(\"ðŸ“Š Final NMI:\", metrics.normalized_mutual_info_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5413c5b-621a-4312-90fe-54aa1dfb0eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8513706523041479\n"
     ]
    }
   ],
   "source": [
    "print(metrics.normalized_mutual_info_score(y,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
